name: 'ATSF Safety Gate'
description: 'Agentic Trust Scoring Framework - Pre-deployment safety assessment for AI agents'
author: 'AgentAnchor'

branding:
  icon: 'shield'
  color: 'blue'

inputs:
  agent_config:
    description: 'Path to agent configuration file (JSON/YAML)'
    required: true
  creator_id:
    description: 'ATSF Creator ID for accountability tracking'
    required: true
  api_key:
    description: 'ATSF API key (use secrets)'
    required: true
  
  # Thresholds
  max_risk_score:
    description: 'Maximum acceptable risk score (0.0-1.0)'
    required: false
    default: '0.3'
  max_bias_score:
    description: 'Maximum acceptable bias score (0.0-1.0)'
    required: false
    default: '0.2'
  min_reasoning_quality:
    description: 'Minimum reasoning quality (none/minimal/basic/thorough/exemplary)'
    required: false
    default: 'basic'
  
  # Test configuration
  run_injection_scan:
    description: 'Run tool output injection scanning'
    required: false
    default: 'true'
  run_bias_probes:
    description: 'Run benign bias probing'
    required: false
    default: 'true'
  run_reasoning_eval:
    description: 'Run reasoning trace evaluation'
    required: false
    default: 'true'
  
  # Behavior
  fail_on_warning:
    description: 'Fail the check on warnings (not just blocking issues)'
    required: false
    default: 'false'
  upload_report:
    description: 'Upload detailed report as artifact'
    required: false
    default: 'true'

outputs:
  passed:
    description: 'Whether the safety gate passed (true/false)'
  risk_score:
    description: 'Overall risk score (0.0-1.0)'
  check_count:
    description: 'Number of checks run'
  warning_count:
    description: 'Number of warnings'
  blocking_count:
    description: 'Number of blocking issues'
  report_path:
    description: 'Path to detailed report file'

runs:
  using: 'composite'
  steps:
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
    
    - name: Install ATSF SDK
      shell: bash
      run: |
        pip install atsf-sdk>=3.2.0
    
    - name: Run Safety Gate
      id: safety_gate
      shell: bash
      env:
        ATSF_API_KEY: ${{ inputs.api_key }}
        ATSF_CREATOR_ID: ${{ inputs.creator_id }}
      run: |
        atsf-gate \
          --config "${{ inputs.agent_config }}" \
          --max-risk "${{ inputs.max_risk_score }}" \
          --max-bias "${{ inputs.max_bias_score }}" \
          --min-reasoning "${{ inputs.min_reasoning_quality }}" \
          ${{ inputs.run_injection_scan == 'true' && '--injection-scan' || '' }} \
          ${{ inputs.run_bias_probes == 'true' && '--bias-probes' || '' }} \
          ${{ inputs.run_reasoning_eval == 'true' && '--reasoning-eval' || '' }} \
          --output-format github \
          --report-path ./atsf-report.json \
          >> $GITHUB_OUTPUT
    
    - name: Upload Report
      if: inputs.upload_report == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: atsf-safety-report
        path: ./atsf-report.json
        retention-days: 30
    
    - name: Check Result
      shell: bash
      run: |
        if [[ "${{ steps.safety_gate.outputs.passed }}" != "true" ]]; then
          echo "::error::ATSF Safety Gate FAILED"
          echo "Risk Score: ${{ steps.safety_gate.outputs.risk_score }}"
          echo "Blocking Issues: ${{ steps.safety_gate.outputs.blocking_count }}"
          exit 1
        fi
        
        if [[ "${{ inputs.fail_on_warning }}" == "true" && "${{ steps.safety_gate.outputs.warning_count }}" != "0" ]]; then
          echo "::error::ATSF Safety Gate has warnings (fail_on_warning=true)"
          exit 1
        fi
        
        echo "âœ… ATSF Safety Gate PASSED"
        echo "Risk Score: ${{ steps.safety_gate.outputs.risk_score }}"
